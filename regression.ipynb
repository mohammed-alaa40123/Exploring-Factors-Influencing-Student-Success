{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe=Pipeline([('ore',ore()),('Normalizer',Normalizer()),('Ridge',Ridge())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Score:  6.814785666682278\n",
      "R^2 Score:  0.0004700582149368415\n",
      "[(0.7050592034445631, 'avg_Grade')]\n",
      "[3.5822934019246255e-39]\n",
      "[13.093597711584877]\n"
     ]
    }
   ],
   "source": [
    "pipe.fit(X,y)\n",
    "y_pred_norm=pipe.predict(X)\n",
    "y_pred=denormalize(y_pred_norm)\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "print(\"MSE Score: \",mse)\n",
    "rs=r2_score(y,y_pred)\n",
    "print(\"R^2 Score: \",rs)\n",
    "enc=ore()\n",
    "\n",
    "X1=enc.fit_transform(X)\n",
    "\n",
    "encoded_df = pd.DataFrame(X1,columns=enc.get_feature_names_out(X.columns))\n",
    "\n",
    "nc,ps,zs=significance_hypothesis_test(encoded_df,y,y_pred,pipe.named_steps['Ridge'].coef_)\n",
    "print(sorted(nc))\n",
    "print(ps)\n",
    "print(zs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(y):#this is a denormalize function\n",
    "    u=np.mean(df['G3'])\n",
    "    sigma=np.std(df['G3'])\n",
    "    for i in y:\n",
    "        i=i*sigma+u\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import scipy.stats as stats\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder as ore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cleaned_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df.drop(columns=[\"G3\"])\n",
    "y = df['G3']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First we will define our features and our target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Score:  1.9372166794863541\n",
      "R^2 Score:  0.7158669150317205\n",
      "Started\n"
     ]
    }
   ],
   "source": [
    "def significance_hypothesis_test(X,y_train,y_pred,coeff):\n",
    "    N=len(y_train)\n",
    "    numerator=np.sqrt(mean_squared_error(y_train,y_pred)*(N/(N-2)))\n",
    "    SE=[]\n",
    "   \n",
    "    cols=X.columns.copy()\n",
    "    for column in cols:\n",
    "        denomenator=np.sqrt(np.std(X[column])*N)\n",
    "        SE.append(numerator/denomenator)\n",
    "    Z_score=[]\n",
    "    p_score=[]\n",
    "    new_coeff=[]\n",
    "\n",
    "\n",
    "    for i in range(len(coeff)):\n",
    "        Z_score.append(coeff[i]/SE[i])\n",
    "        p_score.append(2*stats.norm.cdf(-abs(Z_score[i])))\n",
    "        if(p_score[i]<0.05):\n",
    "            new_coeff.append((coeff[i],X.columns[i]))\n",
    "        else:\n",
    "            new_coeff.append((0,X.columns[i]))\n",
    "    return new_coeff,p_score,Z_score\n",
    "    \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "    # def plot_coefficient_significance(coefficients, p_values):\n",
    "    #     # print(coefficients,p_values)\n",
    "    #     fig, ax = plt.subplots()\n",
    "    #     ax.barh(range(len(coefficients)), p_values, color='skyblue')\n",
    "    #     ax.set_yticks(range(len(coefficients)))\n",
    "    #     ax.set_yticklabels([coeff[1] for coeff in coefficients])\n",
    "    #     ax.invert_yaxis()  # Invert y-axis to have the highest coefficient at the top\n",
    "    #     ax.set_xlabel('p-value')\n",
    "    #     ax.set_title('Significance of Coefficients')\n",
    "    #     plt.show()\n",
    "pipe=Pipeline([('ore',ore()),('Normalizer',Normalizer()),('Ridge',Ridge())])\n",
    "\n",
    "pipe.fit(X,y)\n",
    "y_pred_norm=pipe.predict(X)\n",
    "y_pred=denormalize(y_pred_norm)\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "print(\"MSE Score: \",mse)\n",
    "rs=r2_score(y,y_pred)\n",
    "print(\"R^2 Score: \",rs)\n",
    "enc=ore()\n",
    "\n",
    "X1=enc.fit_transform(X)\n",
    "\n",
    "encoded_df = pd.DataFrame(X1,columns=enc.get_feature_names_out(X.columns))\n",
    "\n",
    "# nc,ps,zs=significance_hypothesis_test(encoded_df,y,y_pred,pipe.named_steps['Ridge'].coef_)\n",
    "# print(sorted(nc))\n",
    "# print(ps)\n",
    "# print(zs)\n",
    "print(\"Started\")\n",
    "coefficients, p_values,_ = significance_hypothesis_test(encoded_df,y,y_pred,pipe.named_steps['Ridge'].coef_)\n",
    "#plot_coefficient_significance(coefficients, p_values)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cleaned_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we tried Ridge regression with cross "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Score:  1.6762269005770825\n",
      "R^2 Score:  0.7541464899558549\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "import numpy as np\n",
    "alphas = [0,0.1, 1.0, 10.0]\n",
    "mean_cv_scores = []\n",
    "for alpha in alphas:\n",
    "    # Define the pipeline with Ridge Regression\n",
    "    pipeline = Pipeline([\n",
    "        ('ore',ore()),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('ridge', Ridge(alpha=alpha))\n",
    "    ])\n",
    "        # Define K-Fold Cross-Validation\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # Perform K-Fold Cross-Validation\n",
    "    cv_scores = cross_val_score(pipeline, X, y, cv=kfold)\n",
    "    mean_cv_score = np.mean(cv_scores)\n",
    "    mean_cv_scores.append(mean_cv_score)\n",
    "best_alpha = alphas[np.argmax(mean_cv_scores)]\n",
    "pipe=Pipeline([('ore',ore()),('Normalizer',Normalizer()),('Ridge',Ridge(alpha=best_alpha))])\n",
    "pipe.fit(X,y)\n",
    "y_pred_norm=pipe.predict(X)\n",
    "y_pred=denormalize(y_pred_norm)\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "print(\"MSE Score: \",mse)\n",
    "rs=r2_score(y,y_pred)\n",
    "print(\"R^2 Score: \",rs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we tried only linear regression with the feature we made from previous grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MSE: 0.93\n",
      "Mean R^2: 0.88\n",
      "Train R^2 Score: 0.8775947730876035\n",
      "Test R^2 Score: 0.8791414363302177\n",
      "[(0.9438224181412738, 'avg_Grade')]\n",
      "[4.440419873752014e-50]\n",
      "[14.880068898777415]\n"
     ]
    }
   ],
   "source": [
    "X=df[['avg_Grade']]\n",
    "y=df['G3']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y ,random_state = 104, train_size=0.8, shuffle=True) \n",
    "\n",
    "model=LinearRegression()\n",
    "model.fit(x_train,y_train)\n",
    "y_pred=model.predict(x_test)\n",
    "# Calculate mean and standard deviation of MSE and R2\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"Mean MSE: {:.2f}\".format(mse))\n",
    "print(\"Mean R^2: {:.2f}\".format(r2))\n",
    "\n",
    "\n",
    "y_pred_train = model.predict(x_train)\n",
    "train_r2 = r2_score(y_train, y_pred_train)\n",
    "print(\"Train R^2 Score:\", train_r2)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "y_pred_test = model.predict(x_test)\n",
    "test_r2 = r2_score(y_test, y_pred_test)\n",
    "print(\"Test R^2 Score:\", test_r2)\n",
    "nc,ps,zs=significance_hypothesis_test(X,y_test,y_pred,model.coef_)\n",
    "print(nc)\n",
    "print(ps)\n",
    "print(zs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying Linear Regression with encoding categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "cat = []\n",
    "\n",
    "for i in df:\n",
    "    if (type(df[i][0]) != str):\n",
    "        l.append(i)\n",
    "    else:\n",
    "        cat.append(i)\n",
    "        \n",
    "l.remove(\"G3\")\n",
    "x = df[l].copy()\n",
    "cat = df[cat].copy() # cat is df\n",
    "\n",
    "for i in cat:\n",
    "    unique = cat[i].unique()\n",
    "    uniqueDict = dict()\n",
    "      \n",
    "    for c in range(len(unique)):\n",
    "        uniqueDict[unique[c]] = c\n",
    "        \n",
    "    cat[i] = cat[i].apply(lambda j: uniqueDict[j])\n",
    "        \n",
    "    # for j in cat[i].keys():\n",
    "    #     cat.loc[j, i] = uniqueDict[cat[i][j]]\n",
    "        \n",
    "    cat[i] = cat[i].astype(\"int64\")\n",
    "    x[i] = cat[i].copy()\n",
    "\n",
    "for i in x:\n",
    "    u = np.mean(x[i])\n",
    "    sigma = np.std(x[i])\n",
    "    x[i] = (x[i] - u) / sigma\n",
    "\n",
    "y = df[\"G3\"].copy()\n",
    "\n",
    "for i in y.keys():\n",
    "    u = np.mean(y)\n",
    "    sigma = np.std(y)\n",
    "    y[i] = (y[i] - u) / sigma\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y ,random_state = 104, train_size=0.8, shuffle=True) \n",
    "\n",
    "regr = LinearRegression(fit_intercept = True)\n",
    "regr.fit(x_train, y_train)\n",
    "y_pred = regr.predict(x_test)\n",
    "\n",
    "print(\"MSE Score: \",mean_squared_error(y_test, y_pred))\n",
    "\n",
    "y_pred_train = regr.predict(x_train)\n",
    "train_r2 = r2_score(y_train, y_pred_train)\n",
    "print(\"Train R^2 Score:\", train_r2)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "y_pred_test = regr.predict(x_test)\n",
    "test_r2 = r2_score(y_test, y_pred_test)\n",
    "print(\"Test R^2 Score:\", test_r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we selected the columns with the highest correlation with the target and the rejected column from our hypothesis testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder  as ore\n",
    "from sklearn.preprocessing import OneHotEncoder  as ohe\n",
    "df_copy = df.copy()\n",
    "binary_encoder = LabelEncoder()\n",
    "# These are the columns affecting the target from our hypothesis testing\n",
    "columns = ['school', 'sex', 'address', 'schoolsup', 'higher', 'internet']\n",
    "for col in columns:\n",
    "    df_copy[f'{col}2'] = binary_encoder.fit_transform(df[f'{col}'])\n",
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()\n",
    "binary_encoder = LabelEncoder()\n",
    "# These are the columns affecting the target from our hypothesis testing\n",
    "columns = ['school', 'sex', 'address', 'schoolsup', 'higher', 'internet']\n",
    "for col in columns:\n",
    "    df_copy[f'{col}2'] = binary_encoder.fit_transform(df[f'{col}'])\n",
    "df_copy.head()\n",
    "columns2=[f\"{c}2\"for c in columns]\n",
    "# These features have strong correlation with our targeet variable\n",
    "columns2.extend(['avg_Grade',\"Dalc\",\"failures\",\"Medu\",\"studytime\"])\n",
    "columns2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying Grid search to test different parameters for our ridge model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X = df_copy[columns2]\n",
    "y = df_copy['G3']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Ridge()\n",
    "\n",
    "param_grid = {\n",
    "    'alpha': [0.1, 1.0, 10.0],\n",
    "    'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best MSE Score:\", -grid_search.best_score_)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "test_mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Test MSE:\", test_mse)\n",
    "\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "train_r2 = r2_score(y_train, y_pred_train)\n",
    "print(\"Train R^2 Score:\", train_r2)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "test_r2 = r2_score(y_test, y_pred_test)\n",
    "print(\"Test R^2 Score:\", test_r2)\n",
    "nc,ps,zs=significance_hypothesis_test(X,y_test,y_pred,best_model.coef_)\n",
    "print(nc)\n",
    "print(ps)\n",
    "print(zs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying KNeighborsRegressor with Grid search to find the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "\n",
    "# Assuming df_copy contains your DataFrame and columns2 are the features\n",
    "X = df_copy[columns2]\n",
    "y = df_copy['G3']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create KNN Regressor model\n",
    "model = KNeighborsRegressor()\n",
    "\n",
    "# Define hyperparameters to search\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2]  # 1 for Manhattan distance, 2 for Euclidean distance\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and best MSE score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best MSE Score:\", -grid_search.best_score_)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "test_mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Test MSE:\", test_mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = best_model.predict(X_train)\n",
    "train_r2 = r2_score(y_train, y_pred_train)\n",
    "print(\"Train R^2 Score:\", train_r2)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "test_r2 = r2_score(y_test, y_pred_test)\n",
    "print(\"Test R^2 Score:\", test_r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting shap\n",
      "  Downloading shap-0.45.1-cp312-cp312-win_amd64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: xgboost in c:\\users\\hamdi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\hamdi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from shap) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\hamdi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from shap) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\hamdi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from shap) (1.4.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\hamdi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from shap) (2.1.4)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in c:\\users\\hamdi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from shap) (4.66.4)\n",
      "Requirement already satisfied: packaging>20.9 in c:\\users\\hamdi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from shap) (23.2)\n",
      "Collecting slicer==0.0.8 (from shap)\n",
      "  Downloading slicer-0.0.8-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: numba in c:\\users\\hamdi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from shap) (0.59.1)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\hamdi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from shap) (3.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hamdi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm>=4.27.0->shap) (0.4.6)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in c:\\users\\hamdi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from numba->shap) (0.42.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hamdi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->shap) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hamdi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->shap) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\hamdi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->shap) (2024.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\hamdi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn->shap) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hamdi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn->shap) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hamdi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n",
      "Downloading shap-0.45.1-cp312-cp312-win_amd64.whl (455 kB)\n",
      "   ---------------------------------------- 0.0/455.7 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 30.7/455.7 kB 1.3 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 81.9/455.7 kB 1.1 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 194.6/455.7 kB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 256.0/455.7 kB 1.6 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 307.2/455.7 kB 1.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 368.6/455.7 kB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 389.1/455.7 kB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  450.6/455.7 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 455.7/455.7 kB 1.2 MB/s eta 0:00:00\n",
      "Downloading slicer-0.0.8-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: slicer, shap\n",
      "Successfully installed shap-0.45.1 slicer-0.0.8\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install shap xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = df.select_dtypes(include=['int64','Float64'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = numerical_columns.drop(columns=[\"G3\"])\n",
    "y = numerical_columns[\"G3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_copy[columns2]\n",
    "y = df_copy['G3']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying Ensemblle Learning boosting techniqe called Xgboost with hyperparameter tuning and Kfold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# Define the XGBoost regressor\n",
    "model = xgb.XGBRegressor()\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9],\n",
    "    'reg_alpha': [0, 0.1, 0.5, 1],\n",
    "    'reg_lambda': [0, 0.1, 0.5, 1]\n",
    "}\n",
    "\n",
    "# Perform cross-validation with hyperparameter tuning\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "random_search = RandomizedSearchCV(model, param_distributions=param_grid, n_iter=20, scoring='neg_mean_squared_error', cv=kfold, verbose=1, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "random_search.fit(X, y)\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print(\"Best hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "# Print the mean squared error of the best estimator\n",
    "print(\"Best MSE:\", -random_search.best_score_)\n",
    "\n",
    "# You can also access the best estimator directly\n",
    "best_model = random_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the parameters from our best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Initialize XGBoost Regressor\n",
    "model = xgb.XGBRegressor(\n",
    "   n_estimators=100,  \n",
    "   max_depth=5,       \n",
    "   learning_rate=0.1, \n",
    "   subsample=0.8,     \n",
    "   colsample_bytree=0.8, \n",
    "   random_state=42    \n",
    ")\n",
    "\n",
    "# Use a list to store scores\n",
    "mse_scores = []\n",
    "r2_scores = []\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate mean and standard deviation of MSE and R2\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"Mean MSE: {:.2f}\".format(mse))\n",
    "print(\"Mean R^2: {:.2f}\".format(r2))\n",
    "\n",
    "\n",
    "y_pred_train = model.predict(X_train)\n",
    "train_r2 = r2_score(y_train, y_pred_train)\n",
    "print(\"Train R^2 Score:\", train_r2)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "y_pred_test = model.predict(X_test)\n",
    "test_r2 = r2_score(y_test, y_pred_test)\n",
    "print(\"Test R^2 Score:\", test_r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final model appears to be overfitting the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MSE: 0.84\n",
      "Mean R^2: 0.89\n",
      "Train R^2 Score: 0.8867672403219766\n",
      "Test R^2 Score: 0.8886614243884502\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuAAAADcCAYAAAAx+RT2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABPIklEQVR4nO3dd3gU1f4G8Hd203sICQSREGoIvfdQpMQfglRBEAIqRUCqV6qAXgUBaVIUlXIRsAECUhMQEkAQ6UgLLXRISEhIbzu/P2JWlp0h2c3uzm7yfp6He83Z2XPOzOzOfufMd84IoiiKICIiIiIii1Ap3QEiIiIiopKEATgRERERkQUxACciIiIisiAG4EREREREFsQAnIiIiIjIghiAExERERFZEANwIiIiIiILYgBORERERGRBDMCJiIiIiCyIATgRERERKWbWrFlwc3Mr8LWYmBgIgoBNmzYZVL+x7zMnO6U7QERERERUEH9/fxw9ehTVqlVTuitFxgCciIiIiKyeo6MjmjVrpnQ3TIIpKERERERk9aRSSbKysjBmzBiUKlUKXl5eGD58ODZu3AhBEBATE6Pz/oyMDIwePRre3t7w9/fHBx98gJycHAuvRR4G4ERERESkuJycHL1/Go3mhe+ZPHkyVq5ciUmTJuGnn36CRqPB5MmTJZedNm0aVCoVfv75Z4wYMQILFizAd999Z45VKRBTUIiIrEx2djbWrFkDABgyZAjs7e0V7hERUREIPfP+X9wiu0hqaqrssc7V1VWyPCEhAV999RWmT5+OSZMmAQA6d+6MDh064M6dO3rLN23aFF9++SUAoGPHjjhw4AA2bdqEESNGGLI2JsEAnIiIiIjMSChwCWdnZ0RFRemVf/PNN9i4caPke86fP4+MjAx069ZNp/z111/H/v379Zbv1KmTzt/BwcH4/fffC+ybOTAAJyIiIiIzKjjjWaVSoVGjRnrlO3bskH3PgwcPAAC+vr465X5+fpLLe3l56fzt4OCAjIyMAvtmDswBJyIiIiIzElCYUXBD+fv7AwDi4uJ0ymNjY03elqkxACciIiIiM1LBHCFnrVq14OTkhG3btumUb9261eRtmRpTUIiIiIjIjEw/+g0APj4+eO+99/DZZ5/ByckJ9erVwy+//ILo6GgAeWkt1sp6e0ZERERExYB5RsAB4PPPP8ewYcMwZ84c9OnTB9nZ2dppCD09Pc3SpikIoiiKSneCiIj+xWkIiag4EYWBAABB/N4i7Q0cOBCHDx/GzZs3LdKeMZiCQkRERERmZJ4UFACIjIzEkSNH0LBhQ2g0GuzYsQMbNmzAwoULzdamKTAAJyIiIiKzEf8JwM0Rhru5uWHHjh2YO3cu0tPTERgYiIULF2LcuHFmaM10GIATERERkRmZ75bDhg0b4o8//jBb/ebCAJyIiIiIzEbknB96GIATERERkdmIZswBt1UMwImIiIjIbBiA62MATkRERERmwxQUfQzAiYiIiMhsGIDrYwBORERERGbDFBR9DMCJiIiIyIwYgD+PATgRERERmQ1TUPQxACciIiIis7HlFJR79+4hKioKsbGx6NWrF8qXL4/c3FwkJSXB09MTarXaqHp5SkJEREREZiNCZXOj4KIoYsKECQgMDMSAAQMwYcIEREdHAwBSUlJQsWJFLF261Oj6bWtrEBEREZFNESHY3Cj4/PnzsWTJEnzwwQeIiIiAKIra1zw9PdGzZ09s3rzZ6PoZgBMRERGR2dhiAP7tt99i0KBBmD17NurVq6f3ep06dbQj4sZgDjgRERERmY2tpZ8AwJ07d9CiRQvZ111dXfH06VOj62cATkRERERmo7HBANzPzw937tyRff3kyZOoUKGC0fXb3hYhIiIiIhsiwNbmAu/Zsye+/vpr3LhxQ1smCHnrEB4ejrVr16JPnz5G188AnIiIiIjMRgMBGhsLwD/++GP4+/ujXr16GDRoEARBwNy5c9GqVSu8+uqrqFOnDqZOnWp0/QzAiYiIiMhsbHEaQk9PTxw7dgwffvgh7t27BycnJ0RGRiIxMREzZ87EoUOH4OLiYnT9zAEnIiIiIrOxtRlQ8jk7O2P69OmYPn26yetmAE5EREREZmOrAbg5MQAnIiIiIrOxtfQTAHj77bcLXEYQBKxatcqo+hmAExEREZHZ2NoNmADw+++/a2c9yZebm4sHDx4gNzcXvr6+cHV1Nbp+BuBEREREZDa2OAIeExMjWZ6dnY2VK1di8eLFiIiIMLp+29siRERERGQzbPFR9HLs7e0xevRodOrUCaNHjza6HgbgRERERGQ2tjgPeEHq1q2LqKgoo9/PFBQiIiIiMhtbTEEpSEREBOcBJyIiIiLrZIuj35988olkeWJiIqKionDq1ClMnjzZ6PoZgBMRERGR2dhi/vesWbMky729vVG5cmV8/fXXGDp0qNH1MwAnIiIiIrOxxQBco9GYtX4G4ERERERkNppimANeVAzAiYiIiMhsbCEH/Pbt20a9r0KFCka9jwE4EREREZmR9QfgFStW1HvyZWHk5uYa1R4DcCIiIiIyG1tIQVm9erVRAbixGIATERERkdnYQgrK4MGDLdoeA3AiIiIiMhtbCMAtjQE4ESnu9o0MJDzORrWaLnBxVSvdnRIv/X4anpx4DI+aXnCr7KF0d4jIxtniNIT5jhw5glOnTiEpKUlvakJBEPDRRx8ZVS8DcCJSjEYjYvWXD3DyaDIAwNFRwPAPXkKNOq4K96zkillzFec+PAExRwQEoNrEmqgxra7S3SIiG2aLI+AJCQno0qULjh8/DlEUIQgCRFEEAO1/FyUAt/6seCIqti6cTtUG3wCQmSli/TcPFexRyZadlIXzU07mBd8AIALRCy4g5Ubyi99IRPQCGqhs4kbMZ/3nP//BuXPnsHHjRty4cQOiKGLv3r2Ijo7GiBEjUK9ePdy/f9/o+m1raxBRsXLuZIpeWUJcDrIyzfsEMpKWHJ0EzfPbXgTij8Yq0yEiKhY0EGxuFHzXrl0YPnw4+vbtC3d3dwCASqVClSpVsHz5clSsWBHjxo0zun4G4ESkmLRUmflTbes4XWxoNKJkeW6GcfPcEhHlEWBrB/bExETUrFkTAODm5gYASEn5d9CoU6dO2Lt3r9H1MwAnKkFuJ+Ri/t40zNubhlvxygdV+fl0Eq9YtB/0j1yZ7S4TmCst7cQjPJz6Bx5/eQa5iZlKd4eIZNjiCHi5cuXw8GFeSqSjoyP8/Pxw9uxZ7ev37t0r0rzhvAmTqIQ4fy8Hry5JQso/ccrifenYNcYT9V5W8jAgffASbOxAbQmZqTm4/VcCnL3sUb6et3kakfsxscKMoCfrL+PuoHDtuVr8l2dR5a++UHs7KdsxItJja8E3AISEhCAiIgLTpk0DAPTt2xfz5s2DWq2GRqPB4sWL0blzZ6PrZwBOVELM25uuDb4BIC0LmLsnDT8MzZtmLiVNg5RUDcr6Wu6wYMGHjtm0BxeS8Ov4M8hMzgEAvNzQG90X1IWdo/yUjbmZuUh5kA73l1ygsi/kxU6ZKxKiFe6nh5OP6FwoybqehITVF+E7sYFynSIiSbk2mHAxYcIEREREIDMzE46Ojpg1axYuXLignfUkJCQES5cuNbp+BuBEJcSJmGy9spO38gK6dVuS8Gt4MrJzgMCX7TFtpI9FAnHZDBTS8fv8K9rgGwDunHyCS3sfona3lySXv7n7Hv6YcRoZT7Lg7OuI1p83xMttyhaiJZkrElZ4ppRzP1WvLPXAXQbgRFbIFg/1tWvXRu3atbV/e3t7Y9++fUhMTIRardbemGks2zslISKjpGfpHwIzskWcupCBn3flBd8AcPNONpasTbBIn+TiOgbmumKv6k8DeD0yTnLZzMQsHJz4FzKeZAEA0uMycWDMceSk50gu/yxBZkBdsMZfConPSG6q/kkmESnPFqchvHjxomS5l5dXkYNvgAE4UckmAlHH0/SKz1/JUqAzz7C+AVdlSeRgpz+VDjYfnngMTZbuG7JTc/D4QqIpmyciKjRbvAmzVq1aqFOnDmbPno1r166ZvH4G4EQlhNRos6AC4p4oOBuK3FA3h8B1Sf1uyWyizCTpwLwwI+CiTKQtWOksKM+zwkyZAuXcfYqkz47gyfSDyL70WOnuEJmFLQbgX331FXx9fTFjxgxUr14dDRs2xPz583Hr1i2T1M8AnKiEkJtZRFAy2JWJmKwl5/jJo0ycOxCPhzf1rxIoTT59R+ZGykINYxflvcoTbeREIV/21QQ8qPMdEqdH4ulnf+B+vVXIOBCjdLdIKX9dBTZGAfctkwJoSSIEiDYWgA8fPhz79+/HvXv3sGTJEri6umLy5MmoVKkSmjdvjiVLlvBJmGTb0rJFXI4XkS03BzGZhPTWFZS9OcaKd/nxHbFYNOQ8Ns27iRUjL2L3ytvKdUZiOxm86QrxBtnpH23ld9NKTtwKK2nuUWieZPxbkJWLxOlRFu2DqNEg90ocNEkZBS9M5jNoCdBkEjBgMRAwHPjxsNI9MilbHAHPV6ZMGYwePRpRUVG4ffs2FixYAEEQMHHiRAQEBBhdLwNwUtS6CxqU+zoXNdbkosI3uYiIsZGhNpskFcWJys65LVhnBJ6Rmos939zR2WRHt8Yi9la6Mh2STEGROaWSi6GLcLS3lbjWRrqplXHkjl5Z5vlYi7Wfc+Y+EqsvQmLQIjzxn4P0zyMt1jY9I/IC8P0z2z4nFxi5Eto744uBXAjItblvqD5/f3/UrFkTNWrUgIuLCzQa42MWBuCkmAcpIt7dq0HSP3NTP0wFOm/SIGxXLlIkZuywdbEpGvTZkA63mSmovTgNOy5Z+uCqf/BTeivLXZJUOgU8/n4GcrL1OxFzXn82EouQ2h6Gpu+oCv7xk53v20Z+KZT+PBtKlJq1Jdty92SkDPgZmmvxeX+kZyNtyl7knLhrsfbpHxFn9MuepAKxSRbvirlo1AI0atsMwEVRxIEDBzBixAj4+/sjNDQU27ZtQ79+/RAeHm50vZwHnBTzx30R2c+dPIoA1l0UoVZpsDpU/iEjxrgcL2LOnxrcfCri1UAVPmgkwN4EB4TVZ3Kx4XwuPB0FTGimRqsK0tHKWz9lIOJa3gr//UiDHuszcGWiCyqVskx0I5sbrGQKuMEvWIbctsrJsqYrNAY+NKcwKShF2CFxm27i0XdXINgJ8B8VjFKvvlxwgyWc3HNgLUGTmI7ci/qj7ZlbLsCuUXmL9IH+8VShK2sWJBZiAMDaHDp0CD///DM2bdqE2NhYeHh4oHv37ujbty86dOgAO7uihdAMwEkxwT7yX8iNl0SsDjVdW/HpIlr+kIuEf9IcD93V4GaSgG86FS3IX/xnDsaH549YidhxVYPj79ijXlndoDo5U9QG3/lyNMAPZ7Ixrb1jkfpQVIKCaSCywb/SQ+AycbZcYG52AvQCaLnUIVHuXopC9F2UG3wt4Lwj7ucbuNz3d+3fCTvvoNbeUHh3smwgZ2s/8dJXgCz0GZM529Lce2pwVWJsMnLWHAPiUqDuXQ+qZoFF7Z1+GxfvQVz/B2CvhjC4NYRAX5O3oRjZm4dt7ZqOPI29rX07gTZt2sDNzQ1du3ZF3759ERoaCgcHB5PVzwCcFFPDR0AFd+C2xFX9HBMPNG68pNEG3/lWnxexpJ0I5yIcGL44qhuxZGuAJcdzsaabbgAuF7hFx1tuRFVqAEL53F65PGaFOyY7w4jiG8xoRTl3KOjE487cs/pl889ZPAC3uXBFyXsgDJxFR44Ym4yMBnOBe3npEjkLD8B+/SDY9W9U1B7+28ahKxBfmatNzxEX7gGOzYBQs5iM1MsdVqzyCVjGybWzvWPnL7/8gi5dusDJycks9RefvUs25497omTwDQCOps0+walH+j8quSKQU8Rpy+IkZqc7+8iAoNqCGQ1SayqKgKhg2KJ4oG3D5PZbkbaokW/OuKn/RU6/lFiUnhhH6SsnJmGh74SJtlXOV4e0wXd+vdlTfzNJ3doqP9qimxufkgnxM9O2oaji8LEtgC3mgPfq1ctswTfAEXBSUFy6/FHHy8RZGbJX5Ytar0QAnSVxb6Xs82aUHugVlA6C5fLSlf5FsoXp+AzsYxH6XtBbxedv5gCgkSgzt+JxQqfsZ9/QbZgbKfGEwLtPTNSbf5yVmAL0qOmfTKgY2fs2lD4Omo4t5oCbG0fASTHBPvKvJWaati35+9JMf1CQCqrl2rHsIUmyYwqnVcgFkcoerOWu/Cr2GyLxOyzbFZlOCoXovOwVbxsZubK1cEU6A8VSI+AmqictS7/M1A9EkhrVyJB+4qvRTlwDmk8GHN4AQqYD503ztMNCKRYnji+WqxaQayPHEUthAG5B9+/fR6NGjbBy5Uqlu2IV/nwg/1rbl039RTXPF19ygMJqowD9jomw0qm4le6T3IwxFu7Gi8j1RfaTXpjRtKJMoVLYfpB1M8VZpqm/KOYOUDOygFc/BY5F5829fegi8Op/8+bjJpPQqARoOAquo1inoERFReG3337DhQsX8OTJE9jZ2aFMmTKoU6cOXn31VTRu3FjpLpZo8WnSR+lq3sCKDqY+N3zRcyCNPygIErNTyLcj0StriOgUPCbKBpGKT0NoWLkSZENlmdHHwjxOXva9RsQhSmwqW/t5V3YWFJlyU4xem3pHmHuTRF0EHj83+8u9BOCva0Dz6mZuHPJfTms64BQRR7/1FcsAPCMjA9OnT8fBgwcREBCALl264KWXXkJubi5u376NQ4cOYfv27fj0008RGmrCue7IIHKHltWhKgR4mvbLaq5ZnqQCcKngUfbphBYMUwSJuewEQVD0Jkxb+4ERi/DUsyIp5IkeYMByBrzZVn46bevTBMg8YcnivShK8xY5fkj1yZSb6WGidHm8pR68ZZ2peKak9P1O1qhYBuCff/45Dh48iIEDB+L999+HSqU7mjpu3DgcOHCgwLtbRVFEeno6XFxczNldeo4lb8BT+vhmjhx0+bbkHkWvJGs9Kss9ZdJ6svbMM4W63JNJC6pU/31m37OGnJRYKyv8+Bt6/BUkhxGscMVepDCXh8zavrLNW0KujaafPH36FCtWrMCBAwcQGxuLlStXokmTJkhISMDatWvRrVs3VKlSxai6DQrAU1NT8b///Q9//vkn7t69i7S0NJQpUwavvPIKhg4dCicnJ9y8eRN9+vRB//79MWHCBL06pk6dit9//x27d++Gt7c3AODkyZNYtmwZoqOj4ebmho4dO6JHjx7o27cvhg4diuHDhxe6j1evXsWOHTtQt25djBkzRvKObkEQ0L59e52yEydOYMSIEZg5cybS09Pxyy+/4O7duxg8eDCGDx+Ov//+G5s2bcK5c+fw6NEjqNVqVKlSBQMHDkS7du302jhz5gy+/PJLXLlyBa6urnjllVfQq1cvyT6LoojNmzdj69atuHnzJlQqFYKDgzF06FA0amS6uVStjdz3ccBOEfvfEFHF23RfWEEmV6TIx73C5oBb6wFW0P6PQuRyrZXeYFb2YAy5OSQlyJ0jFO5k08h52aVuJDD3x0ryfFLpz42BJLtroXWQaUbuAU/KktrZJqxeJfelMWEbL2Rjn1sj2GL+9927d9GmTRvcuXMHVatWxeXLl5GSkgIAKFWqFFauXIlbt25hyZIlRtVvUAAeFxeHbdu2oX379ggNDYVarcapU6ewbt06XLlyBcuWLUNgYCCCg4Oxd+9ejB07Fmr1vxM6p6SkIDIyEi1atNAG32fOnMHo0aPh4eGBsLAwuLu7IyIiAmfP6j/YoTB+/z3vaWyvv/66UVNS/fDDD0hKSkL37t3h4+ODMmXKAAAOHjyImJgYdOjQAf7+/khKSsKOHTvwn//8Ry+V5e+//8bIkSPh4uKCQYMGwd3dHeHh4Zg5c6ZkmzNmzMDevXvxyiuvoGvXrsjOzsbu3bsxatQozJs3D23atDFiS1g/H2fpoPh2MjA8Ihf73zDhBRrZm+qKdlAobKytkRtRteiAqv72FkW9IouS/7FXeFxepnmVNf2IyOY1FeFyttz6FZS/aSUnnSqlL2kZSOrzr3gAbIrmTX0iZO7PktxxWC4wN3n71nNlzVxscQT8P//5D5KTk3HmzBn4+fnBz89P5/Xu3btjx44dRtdvUITz0ksvYefOnbCz+/dtb7zxBr766iusWrUKf//9N2rVqoXXXnsN8+bNw9GjR9GqVSvtsvv27UNmZiZee+01bdnChQshCAJWrVqF8uXznmrVp08fDBs2zKgVunYtb27QatWq6b2WlJSkM0JiZ2cHNzc3nWUePnyITZs2oVSpUjrl77zzDkaPHq1T1q9fP/Tv3x+rVq3SCcAXLlwIjUaDVatWISAgQLtO77zzjl6fDhw4gN27d2Pq1Kno2bOnTt1DhgzBggULEBISUkzmt9XVIUCAvSrv6ZHPOygx7WtRmGvzFfl3xhoS46xwFkKlB4Tkdoti3ZK610BuUdmzh0I0Y+T+kBp5VmJb2do4otSVHuWv/hjIxrorrUiXjcxH6fZNSLTBdQkPD8f48eMRHByM+Ph4vdcrVaqEO3fuGF2/Qadd9vb22uA7JycHT58+RWJiIpo0aQIgb+QXADp37gx7e3vs3LlT5/27du2Cp6cnWrduDQCIj4/HxYsX0aZNG23wDeQFxm+++aZRK5SamgoAeoE1APTs2RMdOnTQ/ps+fbreMl26dNELvgHA2dlZ+98ZGRlITExERkYGGjdujJs3b2ovSyQkJODcuXNo06aNNvgG8rZd//799erdtWsXXF1d0bZtWyQmJmr/paSkoHXr1rh//z5u3zZxNFoECQkJyMz8d5LulJQUJCf/e6NKVlaW3gf1wYMHkn+XcRXwbScBKokjuOaZsqK0kS81PV1yffKzF41tQ/KGy3+6/uy2krvZMjMzw6D1ePjwoU6wY9j+kM7UzMh88aTrptznz6+HXMpAalqqydowaj1kZv14+lR3poSi7Y/CrUdsbKx0Z2TayMmWmR/5madRyW4rmVTYzIzMF66HVNCv0ehuRHNsq+dlZWWZfX9YYj0s8rl6JPO5Eg1s4wU3SJpsPV4QvJmijScJCdKV/3PTtdn3h8xxMDPj398HU+xzJdniNITp6enw9fWVff3Z/WEMg6/x//LLL9i8eTNu3LgBzXMzAuR3xtPTE61atUJUVBRSUlLg5uaG+/fv4/Tp0+jduzfs7e0B5M2LDUAnUM0nVVYYrq6uAKANiJ81f/58ZP/z4zRq1CjJ91eoUEGyPCEhAV999RUiIyORIPFlzV/Pe/fuAQAqVqyot0ylSpX0ymJiYpCamopOnTpJr9A/bRu7PUzt+ZOT5090HBwc4OOj+4Qdf39/2b/X/C1Kpmc8eym5qG0AgMszJ1DPym/F2DYEIVM/rv3ntPbZbSV32HF01H3kZ0HrUbZsWZ2/DdkfUrOgQBDg5OgAQOJhGka0Yeh6yI3Wurq6wsHh3/GBorRh1HrI9Mvdzd10bcj029/fX3ucApB32VO8LNkfqTZUKunD+rMBREHb6nkODg5wd3fX+VtnPSQ2l1ql1vnbHNtKv5/2Op8pc352TdOGdPRqrs/Vs/zK+uGJROv5I/CFbUN3CCF/FfLWy1TroXnBMLsp2vD28pKu/J8YxxL7Q4qj07+/D+Zqw1I0attLswkODkZUVJTsfYhbt25F/fr1ja7foAB8/fr1WLx4MZo1a4Z+/fqhdOnSsLe3R1xcHGbNmqUTkHfp0gUHDhzAvn370L17d+zatQuiKKJLly5Gd7YwqlSpggMHDiA6OhpBQUE6rzVo0KDA90vNjCKKIkaPHo2bN2+iX79+CA4OhpubG1QqFX777Tfs2bNH72SksERRhLe3Nz799FPZZSpXrmxU3dbu8F0RkXelX/NwMHFjZrpMWtQH8djaPWOmZvDDZCxGbiJwhXpmwIwfguyHquC+y761oLatZjY95T85hhCs8ilY1rgNpS41mrB62Xlqld4WSrdvOqINBuDjxo1DWFgY6tSpgz59+gAANBoNrl27ho8//hhHjx7F5s2bja7foAB8165dKFeuHL788kudqf3++OMPvWVbtWoFLy8v7Ny5UxuAV6xYEbVq1dIuk392duuW/iNfpcoKo3379vj222+xbds2dO3a1SS501evXkV0dLTkjCxbt27V+btcuXIA8ka2n3fjxg29spdffhm3b99G7dq1S9x0h6cfyf/4DKll4gOPwjm9su1Y8Pgqm2+q6E2Y0qw1D1a0ooBJdhsV4XdO9v7NAuqU/GyV9LPLQpC7NVxJhh6SpCdyMfU6SE+hajJyqRGWOj6bZ05RqyLaWPoJALz11lu4desWpk+fjmnTpgEAQkNDIYoiVCoVZs+eje7duxtdv0GHarVanffgjmc+FDk5OVi7dq3esnZ2dggNDcWZM2ewZ88e3L59W+fmSwAoXbo0goODERkZibt3/x0KzcnJwQ8//GDgquSpWrUqunTpgrNnz2Lp0qWSI9OG/jDkn2w8/75r167h4MGDOmU+Pj6oXbs2IiMjdU4isrOzsXHjRr26u3TpAo1Gg2XLlkm2LZX4X1yUcpbfD6djTXvgkQ/0inZQKPRz7GQiG4sekuRG65W8OcYazkwkyP1WKDYLivSHSnpZufvJCnG0F2WWKWjgX3LmDiWuFthYvKLo+ZyJBn0tsg6GfP6N4e0qXe4unbpocnLHlWIUgGtUamieS0uzBdOmTcP169cxf/58vPfeexg6dCjmzp2LK1euYNKkSUWq26AR8FdeeQXLli3DmDFj0K5dO6SmpmLv3r06s6I867XXXsOPP/6IOXPmQKVS4dVXX9VbZuzYsRg1ahTeeecd9O7dG25uboiIiEBOTg6AQsw/K2HKlClISUnBunXrEBkZifbt2+Oll15CTk4OHj58iP379wP4d7S6IIGBgahUqRLWrVuHjIwMBAQE4Pbt29iyZQuqVKmCS5cu6Sw/fvx4DB8+HO+88w769OmjnYYwN1f/zq4OHTqga9eu+Pnnn3H58mW0bt0aXl5eiI2Nxblz53D37l1s27bN4G1gCzoGqGCvypWcBeWQTGqK8czz1I7C1ih/HLVgkCI7F7pVDoErSjZ2tIHfQ9lDZiEicPlJIQ3/nCpyXmd7g2xWyNAI3Dy90G3DzI20DgacHYD0Z+6F8XQBGhv3gBWDyc97apn2LcDWcsDT0tLQunVrDB06FCNGjMD48eNN3oZBAfjAgQMhiiK2bduGBQsWwMfHBx07dkS3bt20+THPCgoKQuXKlXH9+nU0adJEO6f2sxo2bIilS5di+fLlWLNmDdzd3dGxY0eEhoZi8ODBejepFYaTkxO++OILREZGYseOHdixYweePHkCOzs7lClTBvXq1cO0adMK/ZAbtVqNJUuWYPHixdixYwfS09NRuXJlzJo1C9HR0XoBeJ06dbB8+XIsW7YM//vf/+Dm5qZ9EE+/fv306p85cyYaNWqEX3/9FWvXrkV2djZ8fHwQFBQke7NoceDnKmBVZwGDd4t6ky/IpuQZSS7IzJudxPy/IHKzoFjyMr3UNhCg8LzDcg8DUTiQkn0wnlIBuAHTEIq5cqNphbhPRWYRppOYh7JbVe4+B0N7ZYEvq7k/f56uwI8TgOFf5z2WvrwPsGoU4Gx4/GGUXNkvnmXatwBbS0FxcXHBzZs3zToFtEEBuFqtxpAhQzBkyBC9106cOCH5np9++qnAehs3bqyXxpI/Sl3Q3flyBEFA27Zt0bZt20It36hRI9l1APLy1efOnatX3q5dO8k7ZBs0aIDVq1frlcu10aVLF7PfoGptRFHEt+f1g2/A9Id0O6Wnc5V9xXIHWMnxB0HpEXBrzIKVp7GFH0S5h04VIv6WXTsjVluRLWUDu0eXggcmUwUWDhJpBaYOtuwl2nAw4YPaAKBbE+DVBsCDJ8BLpQC17aVLWDNbC8CBvHzvvXv3GvQ0dkMofk1AFEWd+TSBvBzwDRs2QK1Wo2HDhgr1jMzt8D35VBMXe9O21dhf/8tvpwIcCnrCXwGkjil2BnyrLPmAJdl8d0XzUGVy423vWG1xcqPSRdmdsjOoFHDiIUhcXlYZ8kUwxgvmn7YVkp9zS334TdSMqrHE1L3eJp5QoLKfflmdl03bBgDY2wEVfBUIvm3uzNFgGpUKGhtLqfnoo48QHR2NgQMH4vDhw7h37x4SEhL0/hnLxKeQhsvKykLXrl0RGhqKgIAAJCUlISIiAlevXkVYWBhKly4NAHj8+HGBdbm5uUlOI0jWKTFT/qDjbuJpCN8MUuGTP3LxMO3fspH1BDgVcWjcwxGIf+4ZP9V9JIIRmbP/Gn6WOyDJ3Qaq6D2YsvceWecPkmBNoziyU5bILW98nQWtt4O/M9KTdOeSdwyQubHNVKzzI2IYyRujLbRicudaBm5Yu1EhyF15BEj9d//bTe5YlJ7pEaZ3g9hz6b8FahWEycXoirHcd9lKj4PGsLXgGwBq1qwJALh48aLkJBr5pO7vKwzFA3A7Ozu0bNkSkZGR2iA7ICAAkyZN0skrf/ZR73JmzpyJrl27mq2vZFrVveVfS3rxwxkN5uUk4OgANRac0OBmEvB/gQKG1y16MDW8gRqzj+h++d5rpD964uYooFsNFbZf+jcPwFENDKhn4qH+F5AMakXL5MAbTumcIbngVqEfRIlm5bZQkWZUM/LN5UYF4/r7R3XLRtcsTIsmZlsBi0YqL0jhAFxdwcugalSVSsPx2ETkLD4IMS4F6jfqw25A46L37xlCj0bA7okQV0UB9moII1+B0LKaSdtQltz3zhqPzcaxxQB8xowZ1pMDbg5qtRozZ84scLnly5cXuExxfWBNcXUuTv61ThVN/6Gv6Clg6SumvbQ4q40aIoD153Ph5SRgUgs12lWUPtCs7eOMD3ZlYteVXFQqJeDTjg542cuCByWZWVCUJLuXFe6m3E2zit6w+hzZTSQ7h2Jh+m7cevuPCkZuSg4efnsZgp0K5d4Phl9/C80gocN69k9hqAQBemNnFgq6VF7OUNf3R+5p3ceVO/aubXhdtcrB4bv+puqaJCG0DoTQOmZtQzFy0yAWowDcFnPAZ82aZdb6FQ/AC6tp06ZKd4FMrJ6f5MPR0bwcsLyDbZwt26sFzG5vh9ntC/4qeTsLWNVLyRQpiSkIBelypVnr746qiPcMGM2AWVBkpxAqzG42cmIMQRDw8uS6eHly3UI0Yj5W+rGRJbjp59oJjpb7WXbf2BfJ/X5C7tkHELyc4PJpR9jVtZ7Hl5cYofWB//6iW+brAfh5KtMfM7DFEXBzs5kAnIqfKt4CZrZQ4ZOjGmjEvJvp54UIGNuQd59bitJj4sY++dzcvMo4QlDpzxxSvrqZ85oNILvt5GY0yy14q4oywbso8UAzxUl8eG0tZdapTQWkXNJ92JpDPf3pes1FHeQHrzPvQ/PgKYRSLhYN/ukZLYKAkaHAij15f7s4At+NBOyKz2+hLQbgn3zySYHLCIKAjz76yKj6+W0jRc1socKgYAF/x4toUlZAGVdbG8OyHdLXG5RNq5CbdUPpEXBXT3u06l0Wh35+qC0Lau6Fl4PcFOzVcwwdrS7ENpXLd7Sm1BstqfW0wm6+iOfkFkj7NRqaR6kAAMHFHt5z2lq8Hyp/D4u3Sc9ZPgx4//+Aaw+BlkGAtxUda0zAFgPwF6Wg5D8VngE42bRALwGBXjb2y2mD5LJ7FQ1aZAI+a5gFpeOQ8qhc3wO3LqSgTEVnBDXzUrpLumRnLDG+StkZMKzx62lIWo6VsgvwRLm/hyL1hwsQ03Pg2jcYdgHFJ+2ADBRUPu9fMST7dGErppG48qfRaHDr1i0sX74cUVFR2L17t9H1MwAnKjEkcsBFEb6l9C9zKj0CbS2hVKV6HqhUzzpHB+VuFJWfHqUQdcqdEFnjDVRyk/rYGHVpF3i8b9pZQ4isjS2OgEtRqVQIDAzEF198gQEDBuD9999/4RSFL6zLxH0jIqsl/eSSds30H5pRP9hCj2CWY4OBlDlJxcXOXtJTWNo7SY+r2Ek9TVCvIelim/nttMLzBCICcgUVcotyec4KhYSEYNeuXUa/v3htDSJ6AYn8b0FEnSAnDO7lAWenvOilZlUHjBlcytKde65fijZvdcrU0B+Fr9JW+mY9vwY+emkoKgcVStUoOLVB9kGYhbiB0xrwY0NknWzxSZgFOXHiBFRFWCemoBCVEPZq/aRZ+3+OHb1f9UC3Du7IyNTAw81yd96b43HqxdErHwbh1/FnkJaQ97TBSq1KI6izdADuWtYZjT+sjb/m/w0xV4TKXkDzGXXh6FmIx8vKzaAiN7WhkqRywB2Lz6wRRMWJaIOjKuvWrZMsT0xMRFRUFLZs2YJ3333X6PoZgBOVEMH+dohNztYpC/L/9xDgYC/AoTBpCiYkO2GH7R2rzcqvmjve2dIC984mwtnLAX7V3F+4fO13q6JSl5eQEP0UpWt6wbl04eafl3+KvfXtEJWnAzSJWTplzs3KKtQbInqRXGu8j6QAgwcPln2tdOnSmDx5MmbMmGF0/QzAiUqIiZ2ccehaNnL/GeVUCcAHnZwV7ZPKimdBsTZ2jmoENPEp9PKu/i5w9dfP738R+VlQrG9/+E1pjIeTjmj/Vnk7wmdoLQV7RERybDH95ObNm3plgiDA29sb7u4vHgQpDAbgRCVE66r22DXGA2v/yIQoAmHNHdG8svSNfBYjG9fZ3mhJcSDI/Uha4Y+n74cNYR/gjqebr8GurCt8xtaF/UvFa+5kouLCFkfABUGAr68vnJ2lB6rS09MRFxeHChUqGFU/A3CiEqRpoD2aBiocdD/DzUPmEGR9A64lgqCyoXnAAXj1rQavvtWU7gYRFUC01oPICwQGBuL7779H//79JV/fvn07+vfvj9zcXKPqt75hDSIqMeo20h+x9C1rDwdHHpqUIPcYe5Xa9n48ich65KpUyLXCK2kvUlAqZHZ2NmdBISLbVKOuC1q298SR35MAAK5uKgwcwRvplOJW2SPv5oDnZj3xblhaoR4RUXFgKykoT58+RWJiovbv+Ph43L59W2+5xMRE/Pjjj/D39ze6LQbgRKQYQRDw1vCy6NStFBIeZ6NSNWeOfivI0dcJVcfWwNVFF7Vl5ftUhGdtbwV7RUS2zlYewrNo0SJ88sknAPJ+n8aNG4dx48ZJLiuKIj799FOj22IATkSK8/N3gJ9/IeapJrMLnlEPZTqWQ/yxOHjW9obfK8aP8BARAbYzD3inTp3g5uYGURTx4Ycf4s0330SDBg10lhEEAa6urmjYsCEaNWpkdFsMwImISIdPcz/4NPdTuhtEVEzk2EgKSvPmzdG8eXMAQGpqKnr16oVatcwzvSkDcCIiIiIyG1vJAX/WzJkzzVo/A3AiIiIiMhtbyQGXcuTIEZw6dQpJSUnQaHSnihIEAR999JFR9TIAJyIiIiKz0dhIDvizEhIS0KVLFxw/fhyiKEIQBO3UhPn/XZQA3HZPSYiIiIjI6uUIAnJsLAj/z3/+g3PnzmHjxo24ceMGRFHE3r17ER0djREjRqBevXq4f/++0fUzACciIiIis8lVCTaXB75r1y4MHz4cffv2hbu7OwBApVKhSpUqWL58OSpWrCg7RWFhMAAnIiIiIrPJEVTIsbE88MTERNSsWRMA4OaW99TmlJQU7eudOnXC3r17ja7ftrYGEREREdmUXCHvny0pV64cHj58CABwdHSEn58fzp49q3393r17EIqQVsObMImIiIjIbGxlHvBnhYSEICIiAtOmTQMA9O3bF/PmzYNarYZGo8HixYvRuXNno+tnAE5EREREZpNtY+knADBhwgREREQgMzMTjo6OmDVrFi5cuKCd9SQkJARLly41un4G4ERERERkNtk2NgMKANSuXRu1a9fW/u3t7Y19+/YhMTERarVae2OmsRiAExEREZHZ2Fr+94t4eXmZpB7buyZARERERDYjW6VCtsr2Qs7bt29jxIgRqF69OkqVKoWoqCgAwOPHjzFmzBicPn3a6Lo5Ak5EREREZpNpgykoFy9eROvWraHRaNC0aVNcu3YNOTk5AIDSpUvj8OHDSE1NxapVq4yqnwE4EREREZlNhg0G4B9++CG8vLxw7NgxCIIAPz8/nde7dOmCn376yej6be96ABERERHZjGwh758tiYqKwnvvvQdfX1/J+b4rVKiAe/fuGV0/R8CJiIiIyGzSbHAEXKPRwMXFRfb1uLg4ODo6Gl0/R8CJiIiIyGziVQLibexhPA0aNMDOnTslX8vJycGPP/6IZs2aGV0/A3AiIiIiMpssQUCWjY2CT5kyBXv27MF7772Hv//+GwDw6NEj7Nu3D506dcKlS5cwefJko+tnCgoRERERmY+NBd8A8Oqrr2Lt2rUYO3YsvvnmGwDAW2+9BVEU4eHhgXXr1iEkJMTo+hmAExEREZH52GAADgADBw5Ez549ER4ejmvXrkGj0aBy5cro3Lkzn4RJRERERFbMRgLwqVOnol+/fqhTp462zNXVFT169DB5W8wBJyIiIiLzUcEmIs7PP/9cm+8NAPHx8VCr1fj9999N3hZHwImIiIjIjGxjBFyKKIpmqZcBOBERERGZj42koFgSA3AiIiIiMh8bSD+xNAbgRERERGQ+NjQCHhMTg1OnTgEAkpKSAABXr16Fl5eX5PINGjQwqh1BNFdyCxERGSU7Oxtr1qwBAAwZMgT29vYK94iIyHjCtFQAgPiZq8I9eTGVSgXhuZMFURT1yp4tz83NNaotjoATERERkfnYyAB4/sCHJTAAJyIiIiLzsZEUlLCwMIu1xQCciIiIiMzHRgJwS2IATkRERETmw/hbDwNwIiIiIjIfBuB6GIATERERkfkwBUUPA3AiIiIiMh8G4HoYgBMRERGR+TD+1sMAnIiIiIjMhwG4HgbgRERERGQ+TEHRwwCciIiIiMyH8bceldIdICIiIqJiTMALg/BZs2bBzc3NYt2xBhwBJyIiIiLzYQqKHgbgRERERGQ+jL/1MAWFiIiIiMyngBSUgpw/fx6dO3eGq6srPD090bt3b9y+fVv7+jvvvIPWrVtr/378+DFUKhUaN26sLUtJSYG9vT1++eUX4ztiQgzAiYiIiMgq3blzByEhIYiPj8f69evx9ddf49SpU2jTpg2Sk5MBACEhIfjrr7+QkZEBAIiKioKjoyNOnz6tXeaPP/5ATk4OQkJCFFuXZzEFhQpNFEXtB5mIzCc7Oxvp6ekAgKdPn8Le3l7hHhFRceDu7g5BiXxslfFtLlq0CNnZ2QgPD0epUqUAAPXr10dwcDDWrl2L999/HyEhIcjMzMSff/6JNm3aICoqCj169EB4eDiOHDmC0NBQREVFoVq1aihTpoyp1qpIGIBToSUnJ8PT01PpbhCVKOPGjVO6C0RUTCQlJcHDw8Pi7YofGB9uHjp0CO3bt9cG3wAQFBSEunXr4vDhw3j//fcRGBiI8uXLIyoqShuAjxgxAunp6YiMjNQG4NYy+g0wACcDuLu7IykpyWT1paSkoEuXLti5c2eJm37IGnF/WBfuD+vC/WFduD+M4+7urnQXDPbkyRPUq1dPr7xMmTJISEjQ/p0feD99+hRnz55FSEgIUlNTsWnTJmRmZuL48eMYOnSoBXv+YgzAqdAEQTDpmbNKpYJarYaHhwcPoFaA+8O6cH9YF+4P68L9UXKUKlUKsbGxeuWPHj1CtWrVtH+HhIRgwoQJOHjwIEqXLo2goCCkpqZi0qRJOHDgADIzM3Vu1FQab8IkIiIiIqvUqlUr7N+/H0+ePNGWXblyBefOnUOrVq20Zfkj3gsXLtSmmtSrVw/Ozs74/PPP8fLLL6NixYqW7r4sjoATERERkaJyc3OxadMmvfKxY8dizZo16NSpE6ZNm4aMjAxMnz4dFSpUwODBg7XLBQUFwc/PD5GRkfjyyy8BAGq1Gi1btsTu3bsxYMAAS61KoTAAJ8U4ODhg6NChcHBwULorBO4Pa8P9YV24P6wL90fxk5GRgT59+uiVf//994iMjMQHH3yAAQMGQK1Wo2PHjli4cKFeTntISAg2bdqkc7NlmzZtsHv3bqu6ARMABFEURaU7QURERERUUjAHnIiIiIjIghiAExERERFZEANwIiIiIiIL4k2YZHUuXbqEsLAwODo64tChQ0p3p8TJzc3F+vXrcfjwYdy4cQOiKKJq1aoYMWIE6tevr3T3ir2YmBjMmzcP586dg6urK/7v//4PI0eO5OPoFbBv3z7s2rULly9fxtOnT1GhQgX07dsX3bp1U+Zx3qQjLS0NvXv3RmxsLNatW4fg4GClu0RUaAzAyaqIooh58+bB29sbaWlpSnenRMrMzMTatWvx2muvISwsDCqVCr/++itGjBiBZcuWoXHjxkp3sdh6+vQpRowYgQoVKmD+/PmIjY3FokWLkJGRgUmTJindvRJnw4YN8Pf3x7hx4+Dt7Y0///wTn332GR49eoRhw4Yp3b0S77vvvkNubq7S3SAyCgNwsirbt29HYmIiunXrhh9//FHp7pRIjo6O2LZtm85TT5s2bYq+ffti48aNDMDNaPPmzUhNTcX8+fPh6ekJIO+KxNy5c/H222/D19dX4R6WLIsWLYKXl5f278aNGyMpKQkbNmzAu+++C5WKWZxKiYmJwS+//IJx48Zhzpw5SneHyGA8epDVSE5OxrJlyzBhwgTY2fHcUCn5j3d+vqxq1aqIi4tTqFclwx9//IEmTZpog28A6NixIzQaDY4dO6Zgz0qmZ4PvfNWrV0dqairS09Mt3yHSmjdvHnr16oWAgAClu0JkFAbgZDVWrFiBGjVqoHXr1kp3hZ6Tk5OD8+fPIzAwUOmuFGsxMTF6j0p2d3dH6dKlERMTo0ifSNeZM2fg5+cHV1dXpbtSYu3btw/Xr1/Hu+++q3RXiIzGYUayCleuXMH27duxYcMGpbtCEtatW4e4uDj0799f6a4Ua0+fPtV7shuQF4Q/ffpUgR7Rs86cOYPw8HCMGzdO6a6UWBkZGVi0aBFGjhwJNzc3pbtDZDQG4GQWKSkpePz4cYHLvfTSS7Czs8PcuXPRu3dvvdE/Mg1D9sfzs20cO3YMK1euxLvvvosaNWqYq4tEVu3Ro0eYMmUKGjVqhH79+indnRJr1apV8PHxQbdu3ZTuClGRMAAns9i3bx8+/fTTApfbtGkTrly5gpiYGHz22WdITk4GAGRlZQHIywt3cHCAo6OjWftb3BmyP549Cbp8+TImTZqE0NBQDB061Iw9JADw8PBASkqKXnlycrJeXj5ZTnJyMsaMGQNPT0/MmzePN18q5MGDB1i/fj3mz5+v/Z7k5+KnpaUhLS0NLi4uSnaRqNAEURRFpTtBJdvKlSvx7bffyr4eFhaG999/34I9IgC4c+cO3nnnHVSvXh2LFi3ijbEWMHToUHh6euKLL77QlqWkpKBdu3aYMWMGunbtqmDvSqaMjAyMGjUKDx8+xJo1a+Dn56d0l0qsEydOYMSIEbKv16pVC2vXrrVch4iKgL+opLiuXbuiYcOGOmU7duxAREQElixZgrJlyyrUs5Lr8ePHGD16NMqWLYu5c+cy+LaQFi1aYM2aNUhOTtbmgu/btw8qlQrNmjVTuHclT05ODqZMmYKYmBh8++23DL4VVr16dXz99dc6ZdHR0Vi4cCGmTJmCmjVrKtQzIsPxV5UUV65cOZQrV06n7OTJk1CpVGjUqJFCvSq5MjIyMGbMGCQmJmLixIm4fv269jV7e3sEBQUp2LvirVevXvjpp58wceJEvP3224iNjcWSJUvQs2dPzgGugLlz5+LQoUMYN24cUlNTcf78ee1r1atXh4ODg4K9K3nc3d1lfxNq1KjBYxPZFAbgRKQjISEB0dHRAIAJEybovObv74/ffvtNiW6VCB4eHvjqq68wf/58TJw4Ea6urujevTtGjhypdNdKpPy51xcvXqz32vbt2/UGDoiICos54EREREREFsRbuYmIiIiILIgBOBERERGRBTEAJyIiIiKyIAbgREREREQWxACciIiIiMiCGIATEREREVkQA3AiIiIiIgtiAE5EREREZEEMwInIKg0ePBiCICjdDQDA33//DTs7O0RERGjLDh48CEEQsHbtWuU6RlZh7dq1EAQBBw8eNOr9/CxJO3PmDFQqFSIjI5XuCpHJMQAnsqAbN25g2LBhCAoKgouLC7y9vVGjRg2EhYXhwIEDOstWrFgRtWrVkq0rP0B9/Pix5OuXLl2CIAgQBAGHDh2SrSd/mfx/Tk5OqFq1KiZMmICEhATjVrSYmTBhAlq2bImOHTsq3RWLiImJwaxZs3DmzBmlu0IWkpiYiFmzZhl9EmGsF33W6tWrh+7du2PixIngQ7upuLFTugNEJcWJEyfQpk0b2NvbY9CgQahZsybS09Nx9epVhIeHw93dHe3atTNZe6tWrYK7uzucnZ2xevVqtG7dWnbZevXqYeLEiQCAhIQE7Nq1C4sWLUJERAROnjwJBwcHk/XL1hw9ehQRERHYunWrTnlISAjS09Nhb2+vTMfMKCYmBh9//DEqVqyIevXqKd0dsoDExER8/PHHAIC2bdtarN2CPmvjxo1DmzZtsGvXLnTp0sVi/SIyNwbgRBby8ccfIy0tDWfOnEHdunX1Xn/48KHJ2srOzsb333+PPn36wNPTE9988w2+/PJLuLu7Sy7/0ksv4a233tL+PWbMGHTt2hU7duzAtm3b0KdPH5P1zdasWLECpUuXxv/93//plKtUKjg5OSnUK6KSoXXr1qhYsSK+/vprBuBUrDAFhchCrl69Ch8fH8ngGwDKli1rsrZ+++03xMbGIiwsDIMHD0Zqaip++ukng+ro3LkzAODatWuyy3z11VcQBAHbt2/Xe02j0aB8+fI6o1rh4eHo27cvKlWqBGdnZ3h5eaFTp06FzvFs27YtKlasqFceExMDQRAwa9YsnXJRFPHVV1+hYcOGcHFxgZubG9q1a6eX7iMnJycHW7duRYcOHfRGuqXydp8tW7FiBapXrw4nJyfUrl0bO3bsAACcP38eoaGh8PDwgI+PD8aMGYPs7GzJ9bxx4wZef/11eHp6wsPDAz169MCNGzd0ltVoNPjss88QEhKCsmXLwsHBARUqVMB7772H+Ph4yfXavHkz2rZtCy8vL7i4uKB69eoYM2YMsrKysHbtWu2VmCFDhmhTkwozKhoTE4OBAweiTJkycHR0ROXKlTF16lSkpaXpLDdr1iwIgoArV65g6tSpKF++PBwdHVG3bl3s2rWrwHaAf/Ou9+/fj08++QQBAQFwdnZG06ZNcezYMQBAZGQkWrVqBVdXV/j7++O///2vZF1bt25Fy5Yt4erqCjc3N7Rs2RLbtm2TXPbbb79FUFAQHB0dUaVKFSxevFg2PSIpKQmTJk1ClSpV4OjoCF9fX7z55pt6+9BQhd3OL7qPQhAEDB48GEDe5zYwMBBA3kBB/j7P/649+/364YcfUKdOHTg5OaFChQqYNWsWcnJydOou7Pe0MJ81QRDQuXNn7NmzBykpKQZuKSLrxRFwIgupXLkyrly5gi1btqBnz56Fek9ubq5sjndmZqbs+1atWoXAwEC0bt0agiCgfv36WL16Nd59991C9/fq1asAgNKlS8su069fP4wfPx7r1q1Dt27ddF7bv38/7t27p01tAfJ+cBMSEjBo0CCUL18e9+7dw3fffYdXXnkFBw4ceGGajDEGDhyIH374Ab1798aQIUOQmZmJDRs2oGPHjtiyZYten5938uRJpKSkoEmTJga1u3z5cjx58gTvvvsunJyc8OWXX6JHjx745ZdfMHToULz55pvo3r07wsPDsXTpUvj5+WH69Ok6daSmpqJt27Zo2rQp5syZg6tXr2LFihU4duwYTp8+rT1hy8rKwvz589GrVy+8/vrrcHV1xV9//YVVq1bh8OHDeilE06ZNw+zZsxEcHIzx48fD398f169fx+bNm/HJJ58gJCQEU6dOxezZszFs2DDtPilTpswL1/nWrVto0qQJkpKSMHLkSFStWhUHDx7EnDlzcOTIEezfvx92dro/OWFhYbC3t8cHH3yArKwsLF68GN27d0d0dLRkACdl8uTJyM3NxdixY5GVlYUFCxagU6dOWLduHd555x0MGzYMAwYMwM8//4wZM2YgMDBQ52rPihUrMGrUKAQFBWHGjBkA8j6n3bt3x8qVKzFs2DDtsosXL8b48eNRt25dzJ49G2lpafjiiy/g5+en16+kpCS0aNECt2/fxttvv42aNWviwYMHWLFiBZo2bYoTJ04gICCgUOtY1O1ckBo1amDRokUYP348evTooT0+ubm56Sy3fft23LhxA6NGjULZsmWxfft2fPzxx7h16xbWrFlj8LoU9rPWvHlzrFy5EocPH0ZoaKjB7RBZJZGILOKPP/4Q7e3tRQBi1apVxSFDhogrVqwQL168KLl8QECACKDAf3FxcTrvu3fvnqhWq8WZM2dqyxYvXiwCkGwLgNipUycxLi5OjIuLE6Ojo8WFCxeK9vb2oqenp/jo0aMXrlfv3r1FR0dHMSEhQaf8rbfeEu3s7HTen5KSovf+hw8fij4+PuKrr76qUx4WFiY+f4hq06aNGBAQoFfHzZs3RQA667xlyxYRgLhy5UqdZbOzs8WGDRuKFStWFDUazQvXbfXq1SIAcdu2bXqvHThwQAQgrlmzRq+sXLlyYmJiorb87NmzIgBREARx8+bNOvU0aNBALFu2rN56AhDHjh2rU56/TsOHD9eWaTQaMS0tTa9/3333nQhA/Omnn7Rlf/75pwhAbNeunZienq6zvEaj0W4PqXUrSP/+/UUA4s6dO3XKP/jgAxGA+N1332nLZs6cKQIQu3TporMPjh8/LgIQJ0+eXGB7a9asEQGI9evXFzMzM7Xl27ZtEwGIdnZ24l9//aUtz8zMFMuWLSs2a9ZMW5aQkCC6urqKlStXFpOSkrTlSUlJYqVKlUQ3NzfxyZMnoiiK4pMnT0QXFxexRo0aYmpqqnbZO3fuiK6uriIA8cCBA9ryMWPGiE5OTuKZM2d0+h0TEyO6u7uLYWFh2jJDtrch21nqO5QPgE4fpL5Dz7+mUqnEkydPass1Go3YvXt3EYB49OhRbbkh39PCrPuhQ4dEAOIXX3whuwyRrWEKCpGFNG/eHCdPnkRYWBiSkpKwZs0ajBw5EsHBwQgJCZG8LF2xYkVERERI/uvUqZNkO2vXroVGo8GgQYO0ZQMGDIC9vT1Wr14t+Z7w8HD4+vrC19cX1apVw4QJExAcHIzw8HDJ0b1nhYWFITMzUyfFJSUlBb/++itCQ0N13u/q6qqzTHx8PNRqNZo2bYo///zzhe0Yav369XB3d0f37t3x+PFj7b/ExER07doVMTEx2lF+OXFxcQCAUqVKGdT24MGD4enpqf27Tp068PDwQLly5fSufrRq1QoPHz6UvLw+efJknb979OiB6tWr69wQKggCnJ2dAeRdMUlMTMTjx4/Rvn17ANDZrhs2bAAAzJkzRy9/Pf/yvzE0Gg22b9+O+vXr6+XKT5kyBSqVCr/++qve+8aOHavTZuPGjeHm5lbgfnnWe++9pzPCnz+K2rRpUzRq1Ehb7uDggCZNmujUHRERgdTUVIwZMwYeHh7acg8PD4wZMwYpKSnYt28fgLzvSFpaGkaNGgUXFxftsuXLl8eAAQN0+iSKIjZs2ICQkBC89NJLOp8/V1dXNGvWDOHh4YVex3zGbmdT6dixIxo0aKD9WxAEfPjhhwBg1nZ9fHwAALGxsWZrg8jSmIJCZEG1a9fW5gzfunULkZGR+O6773Do0CG8/vrreukCrq6u6NChg2Rd69ev1ysTRRGrV69GnTp1oNFodPK3W7Zsie+//x5z5szRu0TdtGlTfPrppwAAR0dHBAQEoEKFCoVap/wge926dRgxYgSAvBzj1NRUnZMAALh+/TqmTZuGvXv3IjExUec1U8/5fenSJSQnJ78wdeLRo0eoVq2a7Ov5fRINnAKtUqVKemXe3t54+eWXJcsBID4+XueSv5eXl+R9ATVq1MDWrVuRmpqqPaH5+eefsWDBApw+fVovn/zJkyfa/7569SoEQZC9D8FYcXFxSElJQc2aNfVeK1WqFPz9/SVPMKW2k4+Pj2zuupTn68jfnvk5zc+/9mzdN2/eBADJfueX5fc7//+DgoL0lg0ODtb5Oy4uDvHx8doTWykqleHjX8ZuZ1OpUaOGXln+upuz3fzvn7U8F4DIFBiAEykkICAAgwYNwsCBA9G6dWscOXIEx48fR6tWrYyuMzIyEtevXwcAVK1aVXKZHTt2oHv37jplpUuXlg30C2JnZ4f+/ftj8eLFuHbtGqpUqYJ169bB29tbJ8c6JSUFISEhSE1Nxbhx41C7dm24u7tDpVJhzpw5+P333wtsS+4H+PmbwIC8H21fX19s3LhRtr4XzbMOQBs8GTofulqtNqgcMDzIz7dlyxb07dsXTZo0wZIlS/Dyyy/DyckJubm5CA0NhUaj0Vm+KCPdpia3PQzZFsZsa3PL73+HDh0wadIkxfphyPfFmtvN//7JncwQ2SIG4EQKEwQBTZs2xZEjR3Dv3r0i1bV69Wo4Ojpi3bp1kiNsw4cPx6pVq/QC8KIKCwvD4sWLsW7dOgwdOhQHDx7EsGHD4OjoqF1m//79uH//PlavXo0hQ4bovP/5GxDllCpVCidPntQrlxp9q1q1KqKjo9GsWTO9m8kKKz9ANyQlwlQSExPx8OFDvVHwS5cuwc/PTzv6/f3338PJyQkHDhzQSY24fPmyXp3VqlXD7t27cfbs2RfeWGpogO7r6wt3d3dcuHBB77UnT57gwYMHVjmfeP7o+YULF/DKK6/ovHbx4kWdZfL///Lly7LL5vP19YWXlxeePn1q9ImtFEO3c37qVEJCgk4aldT3pTD7/NKlS3plz2+n/HYL+z0tTLv5V/IKOmEmsiXMASeykIiICMkRoPT0dG0+6POXsg2RlJSETZs2oVOnTnjjjTfQu3dvvX/dunXD7t278eDBA6PbkVKvXj3UqVMH69evx/fffw+NRoOwsDCdZfJHJJ8f3QwPDy90/ne1atWQnJyM48ePa8s0Gg0WLVqkt+ygQYOg0WgwZcoUyboePXpUYHv169eHh4eHdlo7S/v88891/v71119x5coVnRMotVoNQRB0RrpFUdSmFD2rf//+AICpU6ciKytL7/X8fZN/wlLYkX+VSoWuXbvi9OnT2LNnj946aDQa9OjRo1B1WVLHjh3h6uqKpUuXIjk5WVuenJyMpUuXws3NTfv0044dO8LZ2RnLly/Xme7v7t27eldZVCoVBgwYgOPHj2PTpk2SbRuTz2zods5Pr8rPY8+3YMECvboLs88jIiJw6tQp7d+iKGLevHkAoPOZNOR7Wph2jx07Bjs7O7Rs2VJ2GSJbwxFwIgsZP3484uPj0a1bN9SuXRsuLi64c+cONm7ciOjoaAwaNAi1a9c2uv4ffvgB6enp6NWrl+wyvXr1wtq1a/G///1P7wa/ogoLC8PEiRMxd+5cVKtWDc2aNdN5vVWrVihbtiwmTpyImJgYlC9fHmfOnMH333+P2rVr4/z58wW2MWzYMCxYsAA9evTA2LFj4eDggE2bNkme2ORPPbhs2TKcOnUKr732GkqXLo27d+/i6NGjuHbtWoF5q2q1Gj179sTWrVuRmZmpM6JvbqVLl8aWLVtw//59tG3bVjsNYZkyZXTmO+/duzc2b96M9u3bY9CgQcjOzsbWrVv15oQGgCZNmmDSpEmYO3cuGjRogL59+6Js2bK4efMmNm3ahOPHj8PLywvBwcFwd3fHihUr4OLiAi8vL/j5+Wlv7JQye/ZsREREoHv37hg5ciSqVKmCqKgo/PTTTwgJCdE7IbMGXl5emDdvHkaNGoWmTZtq58Veu3Ytrl27hpUrV2pvpvX29sZ///tffPDBB2jRogUGDRqEtLQ0fP3116hatSpOnz6tU/dnn32GI0eO4I033sAbb7yBZs2awcHBAbdu3cKuXbvQsGFDnTnkC8uQ7fzmm29i6tSpGDZsGC5fvoxSpUphz549klOb+vj4oEqVKvjxxx9RuXJllClTBq6urujatat2mbp166J9+/YYNWoU/P39sW3bNuzbtw8DBw5E8+bNtcsZ8j0t6LMmiiL27NmD0NBQo69kEVklReZeISqB9u7dK44cOVKsU6eO6OPjI6rVarFUqVJi27ZtxVWrVom5ubk6ywcEBIg1a9aUrS9/irH8aQgbNWok2tnZ6U0H+KyMjAzR3d1drFatmrYM/0wHV1QPHz4U7ezsRADip59+KrnM2bNnxc6dO4teXl6im5ub2KZNGzEqKkpyujS5KdR27twp1q1bV3RwcBD9/f3FDz/8ULx8+bLsFGrr1q0TW7VqJbq7u4uOjo5iQECA2KNHD/HHH38s1HrlT923adMmnfIXTUMoNaVaQECA2KZNG73y/Cn5bt68qS3Ln8bt+vXrYrdu3UR3d3fRzc1N7Natm3j16lW9Or755huxRo0aoqOjo1i2bFlx6NChYnx8vN5Uc/k2btwotmjRQnRzcxNdXFzE6tWri2PHjtWZzm/nzp1i/fr1RUdHRxGAZN+fd+PGDfGtt94SfX19RXt7ezEwMFCcMmWKzrR9cutc0HZ6Xv40hM9O/ZdPbr3lPlNbtmwRmzdvLrq4uIguLi5i8+bNxV9//VWy3a+//lqsVq2a6ODgIFauXFlctGiRdrrK5/uSmpoqfvLJJ2KtWrVEJycn0c3NTQwKChLfffdd8dixY9rlDJ32sbDbWRRF8dixY2KLFi1ER0dH0cfHRxw6dKj45MkTyW30559/ii1atBBdXFxEANqpBJ+dPnDjxo1i7dq1RQcHB7F8+fLiRx99JGZlZem1a8j39EWftYMHD4oAxB07dhRq2xDZCkEUjbzzh4iohAgNDUVqaioOHTpkkfbatm2LmJgYxMTEWKQ9oheJiYlBYGAgZs6cqfe0WXPr0aMH7ty5g7/++stqbh4mMgXmgBMRFWDBggU4evSoUXM3E5FxTp8+jW3btmHBggUMvqnYYQ44EVEBatasafap24hIV/369fWm0SQqLjgCTkRERERkQcwBJyIiIiKyII6AExERERFZEANwIiIiIiILYgBORERERGRBDMCJiIiIiCyIATgRERERkQUxACciIiIisiAG4EREREREFsQAnIiIiIjIgv4fB6T2MdlwrLkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x190 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import shap\n",
    "# Initialize XGBoost Regressor\n",
    "model = xgb.XGBRegressor(\n",
    "   n_estimators=100,  \n",
    "   max_depth=3,       \n",
    "   learning_rate=0.1, \n",
    "   subsample=0.9,    \n",
    "   reg_alpha=5, \n",
    "   reg_lambda=5,\n",
    "   colsample_bytree=0.7, \n",
    "   random_state=42    \n",
    ")\n",
    "\n",
    "# Use a list to store scores\n",
    "mse_scores = []\n",
    "r2_scores = []\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate mean and standard deviation of MSE and R2\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"Mean MSE: {:.2f}\".format(mse))\n",
    "print(\"Mean R^2: {:.2f}\".format(r2))\n",
    "\n",
    "\n",
    "y_pred_train = model.predict(X_train)\n",
    "train_r2 = r2_score(y_train, y_pred_train)\n",
    "print(\"Train R^2 Score:\", train_r2)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "y_pred_test = model.predict(X_test)\n",
    "test_r2 = r2_score(y_test, y_pred_test)\n",
    "print(\"Test R^2 Score:\", test_r2)\n",
    "\n",
    "explainer = shap.Explainer(model,X)\n",
    "shap_values= explainer(X)\n",
    "shap.plots.beeswarm(shap_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After  adding reguralization the overfitting is much less"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "76d7c06053c3456e5600312cec90888656fc0ed30c03d8425b9dac6e4fc8e014"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
