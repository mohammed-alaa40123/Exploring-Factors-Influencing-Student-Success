{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import scipy.stats as stats\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder as ore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cleaned_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df.drop(columns=[\"G3\"])\n",
    "y = df['G3']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First we will define our features and our target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(y):#this is a denormalize function\n",
    "    u=np.mean(df['G3'])\n",
    "    sigma=np.std(df['G3'])\n",
    "    for i in y:\n",
    "        i=i*sigma+u\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def significance_hypothesis_test(X,y_train,y_pred,coeff):\n",
    "    N=len(y_train)\n",
    "    numerator=np.sqrt(mean_squared_error(y_train,y_pred)*(N/(N-2)))\n",
    "    SE=[]\n",
    "   \n",
    "    cols=X.columns.copy()\n",
    "    for column in cols:\n",
    "        denomenator=np.sqrt(np.std(X[column])*N)\n",
    "        SE.append(numerator/denomenator)\n",
    "    Z_score=[]\n",
    "    p_score=[]\n",
    "    new_coeff=[]\n",
    "  \n",
    "\n",
    "    \n",
    "\n",
    "    for i in range(len(coeff)):\n",
    "        Z_score.append(coeff[i]/SE[i])\n",
    "        p_score.append(2*stats.norm.cdf(-abs(Z_score[i])))\n",
    "        if(p_score[i]<0.05):\n",
    "            new_coeff.append((coeff[i],X.columns[i]))\n",
    "        else:\n",
    "            new_coeff.append((0,X.columns[i]))\n",
    "    return new_coeff,p_score,Z_score\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cleaned_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe=Pipeline([('ore',ore()),('Normalizer',Normalizer()),('Ridge',Ridge())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Score:  1.9372166794863535\n",
      "R^2 Score:  0.7158669150317206\n",
      "[(-4.251631314929467, 'Fjob'), (-4.24955134687962, 'Pstatus'), (-4.246244464433095, 'health'), (-2.8268549964940477, 'school'), (-2.796755298942414, 'freetime'), (-2.350315197494154, 'higher'), (-2.317099544752715, 'famsup'), (-2.23694409223507, 'goout'), (-2.133913356917573, 'guardian'), (-1.9783341842013586, 'famrel'), (-1.966770282517515, 'schoolsup'), (-1.9205200199160264, 'romantic'), (-1.9031221880883968, 'famsize'), (-1.8065716042626958, 'nursery'), (-1.7465399653503237, 'address'), (-1.586755436045184, 'traveltime'), (-1.5483695454272688, 'Fedu'), (-1.2303925922255434, 'sex'), (-1.2237898803374019, 'failures'), (-1.2094972492308063, 'Walc'), (-1.2010520210302487, 'activities'), (-1.0311726293682784, 'absences'), (-0.9807171373741402, 'internet'), (-0.9374703724503006, 'reason'), (-0.8056896158240379, 'Dalc'), (-0.634834404141638, 'paid'), (-0.39803660486462256, 'studytime'), (0, 'Medu'), (0, 'age'), (0.5541087150027664, 'Mjob'), (5.896236681679474, 'avg_Grade')]\n",
      "[1.9815881095229892e-198, 1.5292196909508812e-40, 0.14031180398192136, 1.0392298805142682e-74, 2.8014076733796917e-86, 3.779433661219775e-290, 0.5780512631627259, 2.2371511429986107e-141, 7.23970630053829e-22, 0.0, 7.562536263741839e-57, 5.095621281184388e-122, 7.130184530804484e-88, 2.6362329238228646e-07, 1.4932095389346377e-47, 5.528204863617628e-62, 1.6242236080009846e-137, 2.547407202219434e-06, 2.2424329022686505e-39, 6.738616153805861e-71, 3.615272336990293e-85, 2.120141663125155e-22, 4.2918869950185995e-94, 3.4973696978046976e-136, 0.0, 3.9611686445558254e-294, 5.950400416067291e-21, 2.2381817011571e-90, 0.0, 1.7346754953668322e-178, 0.0]\n",
      "[-30.053222271320724, -13.33095764261693, 1.4746308954434466, -18.28758241179961, -19.686741501136172, -36.4032663301331, 0.5562334673824835, -25.314051014883464, 9.61021584315091, -60.532838602685665, -15.888914881713374, -23.490543049613798, -19.87186645595335, -5.14775443417812, -14.485641996270152, -16.61389725953818, -24.960946511734846, -4.704298175520127, -13.129121341166885, -17.802663669292865, -19.556730663268763, -9.735861182927204, -20.57833299829031, -24.837865703472378, -40.377599790753486, -36.653933573476884, -9.390874729337849, -20.159122034275732, -78.04043482379562, -28.486238262430465, 205.37393133388923]\n"
     ]
    }
   ],
   "source": [
    "pipe.fit(X,y)\n",
    "y_pred_norm=pipe.predict(X)\n",
    "y_pred=denormalize(y_pred_norm)\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "print(\"MSE Score: \",mse)\n",
    "rs=r2_score(y,y_pred)\n",
    "print(\"R^2 Score: \",rs)\n",
    "enc=ore()\n",
    "\n",
    "X1=enc.fit_transform(X)\n",
    "\n",
    "encoded_df = pd.DataFrame(X1,columns=enc.get_feature_names_out(X.columns))\n",
    "\n",
    "nc,ps,zs=significance_hypothesis_test(encoded_df,y,y_pred,pipe.named_steps['Ridge'].coef_)\n",
    "print(sorted(nc))\n",
    "print(ps)\n",
    "print(zs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we tried Ridge regression with cross "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Score:  1.676226900577083\n",
      "R^2 Score:  0.7541464899558548\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "import numpy as np\n",
    "alphas = [0,0.1, 1.0, 10.0]\n",
    "mean_cv_scores = []\n",
    "for alpha in alphas:\n",
    "    # Define the pipeline with Ridge Regression\n",
    "    pipeline = Pipeline([\n",
    "        ('ore',ore()),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('ridge', Ridge(alpha=alpha))\n",
    "    ])\n",
    "        # Define K-Fold Cross-Validation\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # Perform K-Fold Cross-Validation\n",
    "    cv_scores = cross_val_score(pipeline, X, y, cv=kfold)\n",
    "    mean_cv_score = np.mean(cv_scores)\n",
    "    mean_cv_scores.append(mean_cv_score)\n",
    "best_alpha = alphas[np.argmax(mean_cv_scores)]\n",
    "pipe=Pipeline([('ore',ore()),('Normalizer',Normalizer()),('Ridge',Ridge(alpha=best_alpha))])\n",
    "pipe.fit(X,y)\n",
    "y_pred_norm=pipe.predict(X)\n",
    "y_pred=denormalize(y_pred_norm)\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "print(\"MSE Score: \",mse)\n",
    "rs=r2_score(y,y_pred)\n",
    "print(\"R^2 Score: \",rs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we tried only linear regression with the feature we made from previous grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MSE: 0.93\n",
      "Mean R^2: 0.88\n",
      "Train R^2 Score: 0.8775947730876035\n",
      "Test R^2 Score: 0.8791414363302177\n",
      "[(0.9438224181412738, 'avg_Grade')]\n",
      "[4.440419873752014e-50]\n",
      "[14.880068898777415]\n"
     ]
    }
   ],
   "source": [
    "X=df[['avg_Grade']]\n",
    "y=df['G3']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y ,random_state = 104, train_size=0.8, shuffle=True) \n",
    "\n",
    "model=LinearRegression()\n",
    "model.fit(x_train,y_train)\n",
    "y_pred=model.predict(x_test)\n",
    "# Calculate mean and standard deviation of MSE and R2\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"Mean MSE: {:.2f}\".format(mse))\n",
    "print(\"Mean R^2: {:.2f}\".format(r2))\n",
    "\n",
    "\n",
    "y_pred_train = model.predict(x_train)\n",
    "train_r2 = r2_score(y_train, y_pred_train)\n",
    "print(\"Train R^2 Score:\", train_r2)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "y_pred_test = model.predict(x_test)\n",
    "test_r2 = r2_score(y_test, y_pred_test)\n",
    "print(\"Test R^2 Score:\", test_r2)\n",
    "nc,ps,zs=significance_hypothesis_test(X,y_t,y_pred,model.coef_)\n",
    "print(nc)\n",
    "print(ps)\n",
    "print(zs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying Linear Regression with encoding categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Score:  0.4791093138804456\n",
      "Train R^2 Score: 0.7088781113732967\n",
      "Test R^2 Score: 0.7548654187190122\n"
     ]
    }
   ],
   "source": [
    "l = []\n",
    "cat = []\n",
    "\n",
    "for i in df:\n",
    "    if (type(df[i][0]) != str):\n",
    "        l.append(i)\n",
    "    else:\n",
    "        cat.append(i)\n",
    "        \n",
    "l.remove(\"G3\")\n",
    "x = df[l].copy()\n",
    "cat = df[cat].copy() # cat is df\n",
    "\n",
    "for i in cat:\n",
    "    unique = cat[i].unique()\n",
    "    uniqueDict = dict()\n",
    "      \n",
    "    for c in range(len(unique)):\n",
    "        uniqueDict[unique[c]] = c\n",
    "        \n",
    "    cat[i] = cat[i].apply(lambda j: uniqueDict[j])\n",
    "        \n",
    "    # for j in cat[i].keys():\n",
    "    #     cat.loc[j, i] = uniqueDict[cat[i][j]]\n",
    "        \n",
    "    cat[i] = cat[i].astype(\"int64\")\n",
    "    x[i] = cat[i].copy()\n",
    "\n",
    "for i in x:\n",
    "    u = np.mean(x[i])\n",
    "    sigma = np.std(x[i])\n",
    "    x[i] = (x[i] - u) / sigma\n",
    "\n",
    "y = df[\"G3\"].copy()\n",
    "\n",
    "for i in y.keys():\n",
    "    u = np.mean(y)\n",
    "    sigma = np.std(y)\n",
    "    y[i] = (y[i] - u) / sigma\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y ,random_state = 104, train_size=0.8, shuffle=True) \n",
    "\n",
    "regr = LinearRegression(fit_intercept = True)\n",
    "regr.fit(x_train, y_train)\n",
    "y_pred = regr.predict(x_test)\n",
    "\n",
    "print(\"MSE Score: \",mean_squared_error(y_test, y_pred))\n",
    "\n",
    "y_pred_train = regr.predict(x_train)\n",
    "train_r2 = r2_score(y_train, y_pred_train)\n",
    "print(\"Train R^2 Score:\", train_r2)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "y_pred_test = regr.predict(x_test)\n",
    "test_r2 = r2_score(y_test, y_pred_test)\n",
    "print(\"Test R^2 Score:\", test_r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we selected the columns with the highest correlation with the target and the rejected column from our hypothesis testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G3</th>\n",
       "      <th>avg_Grade</th>\n",
       "      <th>school2</th>\n",
       "      <th>sex2</th>\n",
       "      <th>address2</th>\n",
       "      <th>schoolsup2</th>\n",
       "      <th>higher2</th>\n",
       "      <th>internet2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  ...  \\\n",
       "0     GP   F   18       U     GT3       A     4     4  at_home   teacher  ...   \n",
       "1     GP   F   17       U     GT3       T     1     1  at_home     other  ...   \n",
       "2     GP   F   15       U     LE3       T     1     1  at_home     other  ...   \n",
       "3     GP   F   15       U     GT3       T     4     2   health  services  ...   \n",
       "4     GP   F   16       U     GT3       T     3     3    other     other  ...   \n",
       "\n",
       "  health absences  G3  avg_Grade  school2 sex2 address2 schoolsup2 higher2  \\\n",
       "0      3        4  11        5.5        0    0        1          1       1   \n",
       "1      3        2  11       10.0        0    0        1          0       1   \n",
       "2      3        6  12       12.5        0    0        1          1       1   \n",
       "3      5        0  14       14.0        0    0        1          0       1   \n",
       "4      5        0  13       12.0        0    0        1          0       1   \n",
       "\n",
       "  internet2  \n",
       "0         0  \n",
       "1         1  \n",
       "2         1  \n",
       "3         1  \n",
       "4         0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder  as ore\n",
    "from sklearn.preprocessing import OneHotEncoder  as ohe\n",
    "df_copy = df.copy()\n",
    "binary_encoder = LabelEncoder()\n",
    "# These are the columns affecting the target from our hypothesis testing\n",
    "columns = ['school', 'sex', 'address', 'schoolsup', 'higher', 'internet']\n",
    "for col in columns:\n",
    "    df_copy[f'{col}2'] = binary_encoder.fit_transform(df[f'{col}'])\n",
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['school2',\n",
       " 'sex2',\n",
       " 'address2',\n",
       " 'schoolsup2',\n",
       " 'higher2',\n",
       " 'internet2',\n",
       " 'avg_Grade',\n",
       " 'Dalc',\n",
       " 'failures',\n",
       " 'Medu',\n",
       " 'studytime']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns2=[f\"{c}2\"for c in columns]\n",
    "# These features have strong correlation with our targeet variable\n",
    "columns2.extend(['avg_Grade',\"Dalc\",\"failures\",\"Medu\",\"studytime\"])\n",
    "columns2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying Grid search to test different parameters for our ridge model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'alpha': 10.0, 'solver': 'sparse_cg'}\n",
      "Best MSE Score: 0.7826530227354557\n",
      "Test MSE: 0.9693272722517692\n",
      "Train R^2 Score: 0.8869368045277655\n",
      "Test R^2 Score: 0.8711625341513162\n",
      "[(0, 'school2'), (0, 'sex2'), (0, 'address2'), (-0.40016172888413376, 'schoolsup2'), (0, 'higher2'), (0, 'internet2'), (0.9385614704549294, 'avg_Grade'), (0, 'Dalc'), (0, 'failures'), (0, 'Medu'), (0, 'studytime')]\n",
      "[0.8497351360693214, 0.7946260447686915, 0.9156655903134465, 0.03412901032035006, 0.7133254273309061, 0.6797771428355013, 1.4471951137938119e-47, 0.9571141341575016, 0.4844525583689884, 0.4261551544406482, 0.30523620206470725]\n",
      "[0.18945638454847444, -0.26030820405498045, 0.10589508932379808, -2.118544145824051, 0.3673936234089718, 0.4127672572551604, 14.487792484444284, -0.05377536856081464, -0.6991591788474649, 0.7957881948552687, 1.025269162561113]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X = df_copy[columns2]\n",
    "y = df_copy['G3']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Ridge()\n",
    "\n",
    "param_grid = {\n",
    "    'alpha': [0.1, 1.0, 10.0],\n",
    "    'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best MSE Score:\", -grid_search.best_score_)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "test_mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Test MSE:\", test_mse)\n",
    "\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "train_r2 = r2_score(y_train, y_pred_train)\n",
    "print(\"Train R^2 Score:\", train_r2)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "test_r2 = r2_score(y_test, y_pred_test)\n",
    "print(\"Test R^2 Score:\", test_r2)\n",
    "nc,ps,zs=significance_hypothesis_test(X,y_test,y_pred,best_model.coef_)\n",
    "print(nc)\n",
    "print(ps)\n",
    "print(zs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying KNeighborsRegressor with Grid search to find the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_neighbors': 11, 'p': 2, 'weights': 'uniform'}\n",
      "Best MSE Score: 0.9217446206537115\n",
      "Test MSE: 1.0117302052785921\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "\n",
    "# Assuming df_copy contains your DataFrame and columns2 are the features\n",
    "X = df_copy[columns2]\n",
    "y = df_copy['G3']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create KNN Regressor model\n",
    "model = KNeighborsRegressor()\n",
    "\n",
    "# Define hyperparameters to search\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2]  # 1 for Manhattan distance, 2 for Euclidean distance\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and best MSE score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best MSE Score:\", -grid_search.best_score_)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "test_mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Test MSE:\", test_mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2 Score: 0.8845132058921631\n",
      "Test R^2 Score: 0.8655265775532557\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = best_model.predict(X_train)\n",
    "train_r2 = r2_score(y_train, y_pred_train)\n",
    "print(\"Train R^2 Score:\", train_r2)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "test_r2 = r2_score(y_test, y_pred_test)\n",
    "print(\"Test R^2 Score:\", test_r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from xgboost) (1.23.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from xgboost) (1.9.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = df.select_dtypes(include=['int64','Float64'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = numerical_columns.drop(columns=[\"G3\"])\n",
    "y = numerical_columns[\"G3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_copy[columns2]\n",
    "y = df_copy['G3']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying Ensemblle Learning boosting techniqe called Xgboost with hyperparameter tuning and Kfold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best hyperparameters: {'subsample': 0.8, 'reg_lambda': 0.1, 'reg_alpha': 0.1, 'n_estimators': 300, 'max_depth': 3, 'learning_rate': 0.01, 'colsample_bytree': 0.9}\n",
      "Best MSE: 0.850710649211979\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# Define the XGBoost regressor\n",
    "model = xgb.XGBRegressor()\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9],\n",
    "    'reg_alpha': [0, 0.1, 0.5, 1],\n",
    "    'reg_lambda': [0, 0.1, 0.5, 1]\n",
    "}\n",
    "\n",
    "# Perform cross-validation with hyperparameter tuning\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "random_search = RandomizedSearchCV(model, param_distributions=param_grid, n_iter=20, scoring='neg_mean_squared_error', cv=kfold, verbose=1, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "random_search.fit(X, y)\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print(\"Best hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "# Print the mean squared error of the best estimator\n",
    "print(\"Best MSE:\", -random_search.best_score_)\n",
    "\n",
    "# You can also access the best estimator directly\n",
    "best_model = random_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the parameters from our best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MSE: 1.13\n",
      "Mean R^2: 0.85\n",
      "Train R^2 Score: 0.9603187838841297\n",
      "Test R^2 Score: 0.8503711139456096\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Initialize XGBoost Regressor\n",
    "model = xgb.XGBRegressor(\n",
    "   n_estimators=100,  \n",
    "   max_depth=5,       \n",
    "   learning_rate=0.1, \n",
    "   subsample=0.8,     \n",
    "   colsample_bytree=0.8, \n",
    "   random_state=42    \n",
    ")\n",
    "\n",
    "# Use a list to store scores\n",
    "mse_scores = []\n",
    "r2_scores = []\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate mean and standard deviation of MSE and R2\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"Mean MSE: {:.2f}\".format(mse))\n",
    "print(\"Mean R^2: {:.2f}\".format(r2))\n",
    "\n",
    "\n",
    "y_pred_train = model.predict(X_train)\n",
    "train_r2 = r2_score(y_train, y_pred_train)\n",
    "print(\"Train R^2 Score:\", train_r2)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "y_pred_test = model.predict(X_test)\n",
    "test_r2 = r2_score(y_test, y_pred_test)\n",
    "print(\"Test R^2 Score:\", test_r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final model appears to be overfitting the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MSE: 0.90\n",
      "Mean R^2: 0.88\n",
      "Train R^2 Score: 0.8985868579151443\n",
      "Test R^2 Score: 0.8797864074754093\n",
      "[(0, 'school2'), (0, 'sex2'), (0, 'address2'), (-0.40016172888413376, 'schoolsup2'), (0, 'higher2'), (0, 'internet2'), (0.9385614704549294, 'avg_Grade'), (0, 'Dalc'), (0, 'failures'), (0, 'Medu'), (0, 'studytime')]\n",
      "[0.8445050520613454, 0.7875576494934906, 0.912704678208583, 0.028291670600175015, 0.7036905045892259, 0.669148905290768, 7.514861031832456e-51, 0.9556040379158879, 0.4691867039354767, 0.4100316438920961, 0.28850470332002875]\n",
      "[0.19613429748514075, -0.26948348483278056, 0.10962765388534702, -2.193218078782363, 0.3803434252140608, 0.4273163779597795, 14.99845469879079, -0.05567082977866756, -0.7238029729130055, 0.823837945165534, 1.0614076026593409]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Initialize XGBoost Regressor\n",
    "model = xgb.XGBRegressor(\n",
    "   n_estimators=100,  \n",
    "   max_depth=3,       \n",
    "   learning_rate=0.1, \n",
    "   subsample=0.9,    \n",
    "   reg_alpha=5, \n",
    "   reg_lambda=5,\n",
    "   colsample_bytree=0.7, \n",
    "   random_state=42    \n",
    ")\n",
    "\n",
    "# Use a list to store scores\n",
    "mse_scores = []\n",
    "r2_scores = []\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate mean and standard deviation of MSE and R2\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"Mean MSE: {:.2f}\".format(mse))\n",
    "print(\"Mean R^2: {:.2f}\".format(r2))\n",
    "\n",
    "\n",
    "y_pred_train = model.predict(X_train)\n",
    "train_r2 = r2_score(y_train, y_pred_train)\n",
    "print(\"Train R^2 Score:\", train_r2)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "y_pred_test = model.predict(X_test)\n",
    "test_r2 = r2_score(y_test, y_pred_test)\n",
    "print(\"Test R^2 Score:\", test_r2)\n",
    "nc,ps,zs=significance_hypothesis_test(X,y_test,y_pred,best_model.coef_)\n",
    "print(nc)\n",
    "print(ps)\n",
    "print(zs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After  adding reguralization the overfitting is much less"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "76d7c06053c3456e5600312cec90888656fc0ed30c03d8425b9dac6e4fc8e014"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
